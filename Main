import pandas as pd
import os
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import (
    precision_score, recall_score, f1_score, 
    roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt
import seaborn as sns

import matplotlib
matplotlib.use('Qt5Agg')

data = pd.read_csv(r"C:\Users\Dhruv\Desktop\creditcard.csv", encoding='utf-8', nrows=1000)

majority = data[data.Class == 0]
minority = data[data.Class == 1]
minority_upsampled = resample(minority, 
                              replace=True,     # sample with replacement
                              n_samples=len(majority),    # to match majority class
                              random_state=42)
upsampled = pd.concat([majority, minority_upsampled])
data = upsampled.sample(frac=1, random_state=42).reset_index(drop=True)

X = data.drop('Class', axis=1)  # Features
y = data['Class']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(class_weight='balanced', random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_val)
#print(classification_report(y_val, y_pred))
#print(confusion_matrix(y_val, y_pred))

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
}
grid_search = GridSearchCV(RandomForestClassifier(class_weight='balanced'), param_grid, cv=5)
grid_search.fit(X_train, y_train)
predictions = model.predict(X_val)

best_model = grid_search.best_estimator_

# Function to predict if a transaction is fraudulent
def predict_fraud(transaction):
    # Convert the transaction to a DataFrame
    transaction_df = pd.DataFrame([transaction])
    
    # Make sure the DataFrame has the same columns as the training data
    # (excluding the target variable 'Class')
    if transaction_df.shape[1] != X.shape[1]:
        raise ValueError("Transaction data must have the same number of features as the training data.")
    
    # Use the model to predict
    prediction = best_model.predict(transaction_df)
    
    # Return the prediction
    return "Fraudulent" if prediction[0] == 1 else "Not Fraudulent"

# Example transaction data (replace with actual values)
new_transaction = {
    'Time': 123456,  # Example value
    'V1': -1.2,      # Example value
    'V2': 0.5,       # Example value
    'V3': 0.1,       # Example value
    'V4': 0.0,       # Example value
    'V5': 0.3,       # Example value
    'V6': -0.5,      # Example value
    'V7': 0.2,       # Example value
    'V8': 0.1,       # Example value
    'V9': 0.0,       # Example value
    'V10': 0.0,      # Example value
    'V11': 0.0,      # Example value
    'V12': 0.0,      # Example value
    'V13': 0.0,      # Example value
    'V14': 0.0,      # Example value
    'V15': 0.0,      # Example value
    'V16': 0.0,      # Example value
    'V17': 0.0,      # Example value
    'V18': 0.0,      # Example value
    'V19': 0.0,      # Example value
    'V20': 0.0,      # Example value
    'V21': 0.0,      # Example value
    'V22': 0.0,      # Example value
    'V23': 0.0,      # Example value
    'V24': 0.0,      # Example value
    'V25': 0.0,      # Example value
    'V26': 0.0,      # Example value
    'V27': 0.0,      # Example value
    'V28': 0.0,      # Example value
    'Amount': 100.0  # Example value
}

# Make a prediction
result = predict_fraud(new_transaction)
print(result)


def advanced_model_evaluation(model, X_val, y_val):
    # Predictions and probabilities
    y_pred = model.predict(X_val)
    y_pred_proba = model.predict_proba(X_val)[:, 1]
    
    # Comprehensive Metrics
    print("Detailed Model Performance:")
    print("Precision:", precision_score(y_val, y_pred))
    print("Recall:", recall_score(y_val, y_pred))
    print("F1 Score:", f1_score(y_val, y_pred))
    print("ROC AUC Score:", roc_auc_score(y_val, y_pred_proba))
    
    # Confusion Matrix Visualization
    cm = confusion_matrix(y_val, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Confusion Matrix')
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.show(block = True)
    plt.savefig('confusion_matrix.png')
    plt.close()
    # ROC Curve
    fpr, tpr, _ = roc_curve(y_val, y_pred_proba)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label='ROC Curve')
    plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show(block = True)
### the plot stuff is not working for me, if someone can try to fix that
